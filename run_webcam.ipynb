{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e1b0206-2912-4385-97b9-5948ed70dfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp #face detector\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "import torch\n",
    "import torch.nn as  nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Import tkinter for GUI\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, scrolledtext, filedialog\n",
    "import PIL.Image, PIL.ImageTk\n",
    "from threading import Thread, Event\n",
    "import os\n",
    "\n",
    "# Additional imports for audio processing\n",
    "import pyaudio\n",
    "import wave\n",
    "import threading\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import queue\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "\n",
    "# Import transformers for audio processing\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0907155",
   "metadata": {},
   "source": [
    "#### Model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f67038e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.99)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding='same', bias=False)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.99)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(out_channels*self.expansion, eps=0.001, momentum=0.99)\n",
    "        \n",
    "        self.i_downsample = i_downsample\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "        \n",
    "        x = self.relu(self.batch_norm2(self.conv2(x)))\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        \n",
    "        #downsample if needed\n",
    "        if self.i_downsample is not None:\n",
    "            identity = self.i_downsample(identity)\n",
    "        #add identity\n",
    "        x+=identity\n",
    "        x=self.relu(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Conv2dSame(torch.nn.Conv2d):\n",
    "\n",
    "    def calc_same_pad(self, i: int, k: int, s: int, d: int) -> int:\n",
    "        return max((math.ceil(i / s) - 1) * s + (k - 1) * d + 1 - i, 0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        ih, iw = x.size()[-2:]\n",
    "\n",
    "        pad_h = self.calc_same_pad(i=ih, k=self.kernel_size[0], s=self.stride[0], d=self.dilation[0])\n",
    "        pad_w = self.calc_same_pad(i=iw, k=self.kernel_size[1], s=self.stride[1], d=self.dilation[1])\n",
    "\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            x = F.pad(\n",
    "                x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2]\n",
    "            )\n",
    "        return F.conv2d(\n",
    "            x,\n",
    "            self.weight,\n",
    "            self.bias,\n",
    "            self.stride,\n",
    "            self.padding,\n",
    "            self.dilation,\n",
    "            self.groups,\n",
    "        )\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResBlock, layer_list, num_classes, num_channels=3):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv_layer_s2_same = Conv2dSame(num_channels, 64, 7, stride=2, groups=1, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64, eps=0.001, momentum=0.99)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size = 3, stride=2)\n",
    "        \n",
    "        self.layer1 = self._make_layer(ResBlock, layer_list[0], planes=64, stride=1)\n",
    "        self.layer2 = self._make_layer(ResBlock, layer_list[1], planes=128, stride=2)\n",
    "        self.layer3 = self._make_layer(ResBlock, layer_list[2], planes=256, stride=2)\n",
    "        self.layer4 = self._make_layer(ResBlock, layer_list[3], planes=512, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc1 = nn.Linear(512*ResBlock.expansion, 512)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        x = self.relu(self.batch_norm1(self.conv_layer_s2_same(x)))\n",
    "        x = self.max_pool(x)\n",
    "        # print(x.shape)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.extract_features(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        \n",
    "    def _make_layer(self, ResBlock, blocks, planes, stride=1):\n",
    "        ii_downsample = None\n",
    "        layers = []\n",
    "        \n",
    "        if stride != 1 or self.in_channels != planes*ResBlock.expansion:\n",
    "            ii_downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, planes*ResBlock.expansion, kernel_size=1, stride=stride, bias=False, padding=0),\n",
    "                nn.BatchNorm2d(planes*ResBlock.expansion, eps=0.001, momentum=0.99)\n",
    "            )\n",
    "            \n",
    "        layers.append(ResBlock(self.in_channels, planes, i_downsample=ii_downsample, stride=stride))\n",
    "        self.in_channels = planes*ResBlock.expansion\n",
    "        \n",
    "        for i in range(blocks-1):\n",
    "            layers.append(ResBlock(self.in_channels, planes))\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "def ResNet50(num_classes, channels=3):\n",
    "    return ResNet(Bottleneck, [3,4,6,3], num_classes, channels)\n",
    "\n",
    "\n",
    "class LSTMPyTorch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMPyTorch, self).__init__()\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size=512, hidden_size=512, batch_first=True, bidirectional=False)\n",
    "        self.lstm2 = nn.LSTM(input_size=512, hidden_size=256, batch_first=True, bidirectional=False)\n",
    "        self.fc = nn.Linear(256, 7)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)        \n",
    "        x = self.fc(x[:, -1, :])\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbcf9fa-a7cc-4d4c-b723-6d7efd49b94b",
   "metadata": {},
   "source": [
    "#### Sub functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d0fc324-98a8-4efc-bb11-4bec8a015790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pth_processing(fp):\n",
    "    class PreprocessInput(torch.nn.Module):\n",
    "        def init(self):\n",
    "            super(PreprocessInput, self).init()\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = x.to(torch.float32)\n",
    "            x = torch.flip(x, dims=(0,))\n",
    "            x[0, :, :] -= 91.4953\n",
    "            x[1, :, :] -= 103.8827\n",
    "            x[2, :, :] -= 131.0912\n",
    "            return x\n",
    "\n",
    "    def get_img_torch(img):\n",
    "        \n",
    "        ttransform = transforms.Compose([\n",
    "            transforms.PILToTensor(),\n",
    "            PreprocessInput()\n",
    "        ])\n",
    "        img = img.resize((224, 224), Image.Resampling.NEAREST)\n",
    "        img = ttransform(img)\n",
    "        img = torch.unsqueeze(img, 0)\n",
    "        return img\n",
    "    return get_img_torch(fp)\n",
    "\n",
    "def tf_processing(fp):\n",
    "    def preprocess_input(x):\n",
    "        x_temp = np.copy(x)\n",
    "        x_temp = x_temp[..., ::-1]\n",
    "        x_temp[..., 0] -= 91.4953\n",
    "        x_temp[..., 1] -= 103.8827\n",
    "        x_temp[..., 2] -= 131.0912\n",
    "        return x_temp\n",
    "\n",
    "    def get_img_tf(img):\n",
    "        img = cv2.resize(img, (224,224), interpolation=cv2.INTER_NEAREST)\n",
    "        img = tf.keras.utils.img_to_array(img)\n",
    "        img = preprocess_input(img)\n",
    "        img = np.array([img])\n",
    "        return img\n",
    "\n",
    "    return get_img_tf(fp)\n",
    "\n",
    "def norm_coordinates(normalized_x, normalized_y, image_width, image_height):\n",
    "    \n",
    "    x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
    "    y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
    "    \n",
    "    return x_px, y_px\n",
    "\n",
    "def get_box(fl, w, h):\n",
    "    idx_to_coors = {}\n",
    "    for idx, landmark in enumerate(fl.landmark):\n",
    "        landmark_px = norm_coordinates(landmark.x, landmark.y, w, h)\n",
    "\n",
    "        if landmark_px:\n",
    "            idx_to_coors[idx] = landmark_px\n",
    "\n",
    "    x_min = np.min(np.asarray(list(idx_to_coors.values()))[:,0])\n",
    "    y_min = np.min(np.asarray(list(idx_to_coors.values()))[:,1])\n",
    "    endX = np.max(np.asarray(list(idx_to_coors.values()))[:,0])\n",
    "    endY = np.max(np.asarray(list(idx_to_coors.values()))[:,1])\n",
    "\n",
    "    (startX, startY) = (max(0, x_min), max(0, y_min))\n",
    "    (endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
    "    \n",
    "    return startX, startY, endX, endY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b04b4f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioVisualizer:\n",
    "    def __init__(self, frame, height=100, width=200):\n",
    "        self.frame = frame\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        \n",
    "        # Create matplotlib figure\n",
    "        self.fig = Figure(figsize=(width/100, height/100), dpi=100)\n",
    "        self.ax = self.fig.add_subplot(111)\n",
    "        \n",
    "        # Initial empty plot\n",
    "        self.line, = self.ax.plot([], [], color='#3498db', linewidth=2)\n",
    "        self.ax.set_ylim(-0.5, 0.5)\n",
    "        self.ax.set_xlim(0, 100)\n",
    "        self.ax.axis('off')\n",
    "        self.fig.subplots_adjust(left=0, right=1, top=1, bottom=0, wspace=0, hspace=0)\n",
    "        \n",
    "        # Create canvas\n",
    "        self.canvas = FigureCanvasTkAgg(self.fig, master=self.frame)\n",
    "        self.canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Buffer for audio data\n",
    "        self.buffer = [0] * 100\n",
    "    \n",
    "    def update(self, audio_data):\n",
    "        # Convert audio data to normalized values\n",
    "        if audio_data is not None and len(audio_data) > 0:\n",
    "            # Ensure we're getting the right number of samples\n",
    "            samples = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32)\n",
    "            samples = samples / 32768.0  # Normalize\n",
    "            \n",
    "            # Update buffer (sliding window)\n",
    "            self.buffer = self.buffer[len(samples):] + samples.tolist()[:100]\n",
    "            \n",
    "            # Update plot\n",
    "            self.line.set_data(range(len(self.buffer)), self.buffer)\n",
    "            self.canvas.draw_idle()\n",
    "\n",
    "class AudioProcessor:\n",
    "    def __init__(self, visualizer=None, callback=None):\n",
    "        self.CHUNK = 1024\n",
    "        self.FORMAT = pyaudio.paInt16\n",
    "        self.CHANNELS = 1\n",
    "        self.RATE = 16000  # 16kHz for model\n",
    "        self.recording = False\n",
    "        self.frames = []\n",
    "        self.visualizer = visualizer\n",
    "        self.callback = callback\n",
    "        self.audio_queue = queue.Queue()\n",
    "        self.audio = pyaudio.PyAudio()\n",
    "        self.stream = None\n",
    "        \n",
    "        # Speech characteristics\n",
    "        self.speech_metrics = {\n",
    "            \"avg_pitch\": 0,\n",
    "            \"pitch_variation\": 0,\n",
    "            \"speaking_rate\": 0,\n",
    "            \"volume\": 0,\n",
    "            \"clarity\": 0,\n",
    "            \"samples_processed\": 0\n",
    "        }\n",
    "        \n",
    "        # Voice emotions (derived from metrics only)\n",
    "        self.voice_emotions = {\n",
    "            \"confidence\": 0,\n",
    "            \"engagement\": 0,\n",
    "            \"hesitation\": 0,\n",
    "            \"enthusiasm\": 0\n",
    "        }\n",
    "        \n",
    "        # Flag for periodic processing\n",
    "        self.last_process_time = 0\n",
    "        self.processing_interval = 5  # Process every 5 seconds\n",
    "\n",
    "    def start_recording(self):\n",
    "        if self.recording:\n",
    "            return\n",
    "        self.recording = True\n",
    "        self.frames = []\n",
    "        self.last_process_time = time.time()\n",
    "        \n",
    "        # Reset metrics\n",
    "        self.speech_metrics = {\n",
    "            \"avg_pitch\": 0,\n",
    "            \"pitch_variation\": 0,\n",
    "            \"speaking_rate\": 0,\n",
    "            \"volume\": 0,\n",
    "            \"clarity\": 0,\n",
    "            \"samples_processed\": 0\n",
    "        }\n",
    "        \n",
    "        self.voice_emotions = {\n",
    "            \"confidence\": 0,\n",
    "            \"engagement\": 0,\n",
    "            \"hesitation\": 0,\n",
    "            \"enthusiasm\": 0\n",
    "        }\n",
    "        \n",
    "        def callback(in_data, frame_count, time_info, status):\n",
    "            if self.recording:\n",
    "                self.frames.append(in_data)\n",
    "                self.audio_queue.put(in_data)\n",
    "                \n",
    "                # Update visualizer if available\n",
    "                if self.visualizer:\n",
    "                    self.visualizer.update(in_data)\n",
    "                \n",
    "                # Process audio periodically\n",
    "                current_time = time.time()\n",
    "                if current_time - self.last_process_time >= self.processing_interval:\n",
    "                    self.process_audio_chunk()\n",
    "                    self.last_process_time = current_time\n",
    "            return (in_data, pyaudio.paContinue)\n",
    "        \n",
    "        try:\n",
    "            self.stream = self.audio.open(\n",
    "                format=self.FORMAT,\n",
    "                channels=self.CHANNELS,\n",
    "                rate=self.RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=self.CHUNK,\n",
    "                stream_callback=callback\n",
    "            )\n",
    "            print(\"Audio recording started\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error starting audio stream: {e}\")\n",
    "            self.recording = False\n",
    "\n",
    "    def stop_recording(self):\n",
    "        if not self.recording:\n",
    "            return\n",
    "        self.recording = False\n",
    "        \n",
    "        if self.stream:\n",
    "            try:\n",
    "                self.stream.stop_stream()\n",
    "                self.stream.close()\n",
    "                self.stream = None\n",
    "                print(\"Audio recording stopped\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error stopping audio stream: {e}\")\n",
    "\n",
    "    def process_audio_chunk(self):\n",
    "        # Always process/log, even if not enough frames\n",
    "        enough_data = len(self.frames) >= 50\n",
    "        # Take last ~3 seconds of audio, or whatever is available\n",
    "        recent_frames = self.frames[-50:] if enough_data else self.frames\n",
    "        try:\n",
    "            if recent_frames:\n",
    "                audio_data = np.frombuffer(b''.join(recent_frames), dtype=np.int16).astype(np.float32)\n",
    "                audio_data = audio_data / 32768.0  # Normalize to [-1, 1]\n",
    "            else:\n",
    "                audio_data = np.array([])\n",
    "\n",
    "            # Only use direct speech metrics (no HuggingFace model)\n",
    "            direct_metrics_emotions = {\n",
    "                \"confidence\": 0,\n",
    "                \"engagement\": 0,\n",
    "                \"hesitation\": 0,\n",
    "                \"enthusiasm\": 0\n",
    "            }\n",
    "\n",
    "            if len(audio_data) > 0:\n",
    "                # Calculate volume (RMS amplitude)\n",
    "                volume = np.sqrt(np.mean(audio_data**2))\n",
    "                # In AudioProcessor.process_audio_chunk, after volume calculation\n",
    "                if volume > 0:\n",
    "                    volume_db = 20 * np.log10(volume)\n",
    "                else:\n",
    "                    volume_db = -100.0\n",
    "                self.speech_metrics[\"volume_db\"] = volume_db\n",
    "                try:\n",
    "                    # Extract pitch information\n",
    "                    pitches, magnitudes = librosa.piptrack(y=audio_data, sr=self.RATE)\n",
    "                    pitch_values = []\n",
    "                    for i in range(pitches.shape[1]):\n",
    "                        index = magnitudes[:, i].argmax()\n",
    "                        pitch = pitches[index, i]\n",
    "                        if pitch > 0:\n",
    "                            pitch_values.append(pitch)\n",
    "                    \n",
    "                    if pitch_values:\n",
    "                        # Calculate basic speech metrics\n",
    "                        avg_pitch = np.mean(pitch_values)\n",
    "                        pitch_variation = np.std(pitch_values)\n",
    "                        alpha = 0.7  # Smoothing factor\n",
    "                        \n",
    "                        # Update speech metrics with new values\n",
    "                        self.speech_metrics[\"avg_pitch\"] = alpha * avg_pitch + (1 - alpha) * self.speech_metrics[\"avg_pitch\"]\n",
    "                        self.speech_metrics[\"pitch_variation\"] = alpha * pitch_variation + (1 - alpha) * self.speech_metrics[\"pitch_variation\"]\n",
    "                        self.speech_metrics[\"volume\"] = alpha * volume + (1 - alpha) * self.speech_metrics[\"volume\"]\n",
    "                        self.speech_metrics[\"samples_processed\"] += 1\n",
    "                        \n",
    "                        # Calculate speaking rate from zero crossings\n",
    "                        zero_crossings = librosa.zero_crossings(audio_data)\n",
    "                        speaking_rate = sum(zero_crossings) / len(audio_data) * self.RATE / 100\n",
    "                        self.speech_metrics[\"speaking_rate\"] = alpha * speaking_rate + (1 - alpha) * self.speech_metrics[\"speaking_rate\"]\n",
    "                        \n",
    "                        # Clarity (spectral centroid)\n",
    "                        spectral_centroids = librosa.feature.spectral_centroid(y=audio_data, sr=self.RATE)[0]\n",
    "                        self.speech_metrics[\"clarity\"] = min(1.0, np.mean(spectral_centroids) / 3000)\n",
    "                        \n",
    "                        # Calculate emotions from direct speech metrics\n",
    "                        # 1. Confidence: Based on volume and steady pitch\n",
    "                        norm_pitch_var = min(1.0, pitch_variation / 200)  # Cap at 200Hz variation\n",
    "                        steady_factor = 1.0 - norm_pitch_var * 0.5  # Steadier voice = more confident (but with less impact)\n",
    "                        volume_factor = min(1.0, volume * 12)  # Louder = more confident, up to a limit\n",
    "                        direct_metrics_emotions[\"confidence\"] = 0.8 * volume_factor + 0.2 * steady_factor\n",
    "                        \n",
    "                        # 2. Enthusiasm: Based on pitch variation and speaking rate\n",
    "                        norm_speaking_rate = min(1.0, speaking_rate / 15)  # Good rate is around 10-15\n",
    "                        direct_metrics_emotions[\"enthusiasm\"] = 0.6 * norm_pitch_var + 0.4 * norm_speaking_rate\n",
    "                        \n",
    "                        # 3. Hesitation: Inverse of speaking rate and confidence\n",
    "                        slow_factor = 1.0 - min(1.0, speaking_rate / 8)  # Slower = more hesitation\n",
    "                        direct_metrics_emotions[\"hesitation\"] = 0.6 * slow_factor + 0.4 * (1.0 - volume_factor)\n",
    "                        \n",
    "                        # 4. Engagement: Based on clarity, pitch variation, and balanced speaking rate\n",
    "                        rate_balance = 1.0 - abs(norm_speaking_rate - 0.5) * 2  # Penalize too fast/slow\n",
    "                        direct_metrics_emotions[\"engagement\"] = 0.4 * self.speech_metrics[\"clarity\"] + 0.3 * norm_pitch_var + 0.3 * rate_balance\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error in audio metrics: {e}\")\n",
    "\n",
    "            # Use only direct metrics for emotions\n",
    "            for emotion in self.voice_emotions:\n",
    "                self.voice_emotions[emotion] = min(1.0, max(0.0, direct_metrics_emotions[emotion]))\n",
    "\n",
    "            # Notify callback if available (always log an interval)\n",
    "            if self.callback:\n",
    "                self.callback(self.speech_metrics, self.voice_emotions)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing audio chunk: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae915fd-cc3d-4dc1-83fc-c9c32e1b12a8",
   "metadata": {},
   "source": [
    "#### Emotion Logging GUI Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8a08427",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionLoggingApp:\n",
    "    def __init__(self, window, window_title):\n",
    "        self.window = window\n",
    "        self.window.title(window_title)\n",
    "        self.window.geometry(\"1200x800\")  # Increased height for audio components\n",
    "        \n",
    "        # Initialize models\n",
    "        self.init_models()\n",
    "        \n",
    "        # Create the UI elements\n",
    "        self.create_ui()\n",
    "        \n",
    "        # Initialize variables\n",
    "        self.is_running = False\n",
    "        self.stop_event = Event()\n",
    "        self.emotion_logs = []\n",
    "        self.current_emotions = []\n",
    "        self.speech_logs = []\n",
    "        self.logging_start_time = None\n",
    "        self.last_log_time = None\n",
    "        self.transcript_file_path = None\n",
    "        self.stopwatch_active = False\n",
    "        self.elapsed_time = 0\n",
    "        \n",
    "        # Start video capture\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.update()\n",
    "        \n",
    "        self.window.protocol(\"WM_DELETE_WINDOW\", self.on_closing)\n",
    "        self.window.mainloop()\n",
    "    \n",
    "    def init_models(self):\n",
    "        # MediaPipe setup\n",
    "        self.mp_face_mesh = mp.solutions.face_mesh\n",
    "        \n",
    "        # Model settings\n",
    "        name_backbone_model = 'FER_static_ResNet50_AffectNet.pt'\n",
    "        name_LSTM_model = 'Aff-Wild2'\n",
    "        \n",
    "        # Load ResNet model\n",
    "        self.pth_backbone_model = ResNet50(7, channels=3)\n",
    "        self.pth_backbone_model.load_state_dict(torch.load(name_backbone_model))\n",
    "        self.pth_backbone_model.eval()\n",
    "        \n",
    "        # Load LSTM model\n",
    "        self.pth_LSTM_model = LSTMPyTorch()\n",
    "        self.pth_LSTM_model.load_state_dict(torch.load(f'FER_dinamic_LSTM_{name_LSTM_model}.pt'))\n",
    "        self.pth_LSTM_model.eval()\n",
    "        \n",
    "        # Emotion dictionary\n",
    "        self.DICT_EMO = {0: 'Neutral', 1: 'Happiness', 2: 'Sadness', 3: 'Surprise', 4: 'Fear', 5: 'Disgust', 6: 'Anger'}\n",
    "        self.NEGATIVE_EMOTIONS = ['Sadness', 'Fear', 'Disgust', 'Anger']\n",
    "        \n",
    "        # Initialize LSTM features\n",
    "        self.lstm_features = []\n",
    "    \n",
    "    def create_ui(self):\n",
    "        # Main frame\n",
    "        main_frame = ttk.Frame(self.window)\n",
    "        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "        \n",
    "        # Left frame for video and transcript\n",
    "        left_frame = ttk.Frame(main_frame)\n",
    "        left_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=5, pady=5)\n",
    "        \n",
    "        # Transcript frame at the top of left frame\n",
    "        transcript_frame = ttk.LabelFrame(left_frame, text=\"Presentation Transcript\")\n",
    "        transcript_frame.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        # Transcript buttons frame\n",
    "        transcript_buttons_frame = ttk.Frame(transcript_frame)\n",
    "        transcript_buttons_frame.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        # Choose file button\n",
    "        self.choose_file_button = ttk.Button(transcript_buttons_frame, text=\"Choose Transcript File\", command=self.choose_transcript_file)\n",
    "        self.choose_file_button.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        # File name label\n",
    "        self.file_label = ttk.Label(transcript_buttons_frame, text=\"No file selected\")\n",
    "        self.file_label.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        # Transcript text area\n",
    "        self.transcript_text = scrolledtext.ScrolledText(transcript_frame, wrap=tk.WORD, height=8)\n",
    "        self.transcript_text.pack(fill=tk.X, padx=5, pady=5)\n",
    "        self.transcript_text.insert(tk.END, \"Load a transcript file to view your presentation text here.\")\n",
    "        \n",
    "        # Video frame\n",
    "        self.video_frame = ttk.LabelFrame(left_frame, text=\"Webcam Feed\")\n",
    "        self.video_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)\n",
    "        \n",
    "        # Create canvas for video\n",
    "        self.canvas = tk.Canvas(self.video_frame)\n",
    "        self.canvas.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Audio visualizer frame below video\n",
    "        audio_viz_frame = ttk.LabelFrame(left_frame, text=\"Audio Input Level\")\n",
    "        # Fix: Remove height parameter from pack and use a fixed height widget\n",
    "        audio_viz_frame.pack(fill=tk.X, padx=5, pady=5)\n",
    "        # Create a fixed-height frame inside\n",
    "        viz_content_frame = ttk.Frame(audio_viz_frame, height=120)\n",
    "        viz_content_frame.pack(fill=tk.X)\n",
    "        viz_content_frame.pack_propagate(False)  # Prevent shrinking\n",
    "        \n",
    "        # Create audio visualizer in the fixed-height frame\n",
    "        self.audio_visualizer = AudioVisualizer(viz_content_frame, height=100, width=800)\n",
    "        \n",
    "        # Right frame for controls and summary\n",
    "        right_frame = ttk.Frame(main_frame, width=300)\n",
    "        right_frame.pack(side=tk.RIGHT, fill=tk.BOTH, padx=5, pady=5, expand=False)\n",
    "        right_frame.pack_propagate(False)  # Prevent the frame from shrinking to fit its contents\n",
    "        \n",
    "        # Control frame\n",
    "        control_frame = ttk.LabelFrame(right_frame, text=\"Controls\")\n",
    "        control_frame.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        # Stopwatch display\n",
    "        stopwatch_frame = ttk.Frame(control_frame)\n",
    "        stopwatch_frame.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        ttk.Label(stopwatch_frame, text=\"Elapsed Time: \").pack(side=tk.LEFT)\n",
    "        self.time_label = ttk.Label(stopwatch_frame, text=\"00:00:00\", font=(\"Arial\", 14, \"bold\"))\n",
    "        self.time_label.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        # Start button\n",
    "        self.start_button = ttk.Button(control_frame, text=\"Start Logging\", command=self.start_logging)\n",
    "        self.start_button.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        # Stop button\n",
    "        self.stop_button = ttk.Button(control_frame, text=\"Stop Logging\", command=self.stop_logging, state=tk.DISABLED)\n",
    "        self.stop_button.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        # Reset button\n",
    "        self.reset_button = ttk.Button(control_frame, text=\"Reset\", command=self.reset_logging, state=tk.DISABLED)\n",
    "        self.reset_button.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        # Status indicator\n",
    "        status_frame = ttk.Frame(control_frame)\n",
    "        status_frame.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        ttk.Label(status_frame, text=\"Status: \").pack(side=tk.LEFT)\n",
    "        self.status_label = ttk.Label(status_frame, text=\"Ready\")\n",
    "        self.status_label.pack(side=tk.LEFT)\n",
    "        \n",
    "        # Voice metrics frame\n",
    "        voice_frame = ttk.LabelFrame(right_frame, text=\"Voice Analysis\")\n",
    "        voice_frame.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        # Voice metrics display\n",
    "        self.voice_labels = {}\n",
    "        metrics = [\"Confidence\", \"Enthusiasm\", \"Clarity\", \"Speaking Rate\"]\n",
    "        \n",
    "        for metric in metrics:\n",
    "            metric_frame = ttk.Frame(voice_frame)\n",
    "            metric_frame.pack(fill=tk.X, padx=5, pady=2)\n",
    "            \n",
    "            ttk.Label(metric_frame, text=f\"{metric}: \").pack(side=tk.LEFT)\n",
    "            self.voice_labels[metric.lower()] = ttk.Label(metric_frame, text=\"N/A\")\n",
    "            self.voice_labels[metric.lower()].pack(side=tk.LEFT)\n",
    "            \n",
    "            # Progress bar for visual representation\n",
    "            progress = ttk.Progressbar(metric_frame, length=150)\n",
    "            progress.pack(side=tk.RIGHT, padx=5)\n",
    "            self.voice_labels[f\"{metric.lower()}_bar\"] = progress\n",
    "        \n",
    "        # Summary frame\n",
    "        summary_frame = ttk.LabelFrame(right_frame, text=\"Analysis Summary\")\n",
    "        summary_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)\n",
    "        \n",
    "        # Create scrolled text for summary\n",
    "        self.summary_text = scrolledtext.ScrolledText(summary_frame, wrap=tk.WORD, width=30, height=20)\n",
    "        self.summary_text.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)\n",
    "        self.summary_text.config(state=tk.DISABLED)\n",
    "        \n",
    "        # Initialize audio processor\n",
    "        self.audio_processor = AudioProcessor(self.audio_visualizer, self.update_voice_metrics)\n",
    "    \n",
    "    def update_voice_metrics(self, speech_metrics, voice_emotions, final=True):\n",
    "        # Update the voice metrics display with new data\n",
    "        if not self.is_running and not final:\n",
    "            return\n",
    "        \n",
    "        # Update confidence\n",
    "        confidence = voice_emotions[\"confidence\"] * 100\n",
    "        self.voice_labels[\"confidence\"].config(text=f\"{confidence:.1f}%\")\n",
    "        self.voice_labels[\"confidence_bar\"][\"value\"] = confidence\n",
    "        \n",
    "        # Update enthusiasm\n",
    "        enthusiasm = voice_emotions[\"enthusiasm\"] * 100\n",
    "        self.voice_labels[\"enthusiasm\"].config(text=f\"{enthusiasm:.1f}%\")\n",
    "        self.voice_labels[\"enthusiasm_bar\"][\"value\"] = enthusiasm\n",
    "        \n",
    "        # Update clarity\n",
    "        clarity = speech_metrics[\"clarity\"] * 100\n",
    "        self.voice_labels[\"clarity\"].config(text=f\"{clarity:.1f}%\")\n",
    "        self.voice_labels[\"clarity_bar\"][\"value\"] = clarity\n",
    "\n",
    "        # --- Add this block ---\n",
    "        volume = speech_metrics[\"volume\"]\n",
    "        scaled_volume = min(100, volume * 100)  # Scale for UI (0-100)\n",
    "        self.voice_labels[\"volume\"] = self.voice_labels.get(\"volume\") or ttk.Label()  # If not present\n",
    "        self.voice_labels[\"volume\"].config(text=f\"{scaled_volume:.1f}\")\n",
    "        if \"volume_bar\" in self.voice_labels:\n",
    "            self.voice_labels[\"volume_bar\"][\"value\"] = scaled_volume\n",
    "        # --- End block ---\n",
    "        \n",
    "        # Update speaking rate\n",
    "        speaking_rate = speech_metrics[\"speaking_rate\"]\n",
    "        rate_percent = min(100, speaking_rate * 5)  # Scale for progress bar\n",
    "        self.voice_labels[\"speaking rate\"].config(text=f\"{speaking_rate:.1f}\")\n",
    "        self.voice_labels[\"speaking rate_bar\"][\"value\"] = rate_percent\n",
    "        \n",
    "        # Log speech data for every interval (not just final)\n",
    "        self.speech_logs.append({\n",
    "            \"metrics\": speech_metrics.copy(),\n",
    "            \"emotions\": voice_emotions.copy()\n",
    "        })\n",
    "\n",
    "    \n",
    "    def choose_transcript_file(self):\n",
    "        file_path = filedialog.askopenfilename(\n",
    "            title=\"Select Transcript File\",\n",
    "            filetypes=[(\"Text files\", \"*.txt\"), (\"All files\", \"*.*\")]\n",
    "        )\n",
    "        \n",
    "        if file_path:\n",
    "            self.transcript_file_path = file_path\n",
    "            filename = os.path.basename(file_path)\n",
    "            self.file_label.config(text=f\"Selected: {filename}\")\n",
    "            \n",
    "            try:\n",
    "                with open(file_path, 'r') as file:\n",
    "                    content = file.read()\n",
    "                    self.transcript_text.delete(1.0, tk.END)\n",
    "                    self.transcript_text.insert(tk.END, content)\n",
    "            except Exception as e:\n",
    "                self.transcript_text.delete(1.0, tk.END)\n",
    "                self.transcript_text.insert(tk.END, f\"Error reading file: {str(e)}\")\n",
    "    \n",
    "    def update_stopwatch(self):\n",
    "        if self.stopwatch_active:\n",
    "            current_time = time.time()\n",
    "            self.elapsed_time = current_time - self.logging_start_time\n",
    "            \n",
    "            # Format time as HH:MM:SS\n",
    "            hours, remainder = divmod(int(self.elapsed_time), 3600)\n",
    "            minutes, seconds = divmod(remainder, 60)\n",
    "            time_str = f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "            self.time_label.config(text=time_str)\n",
    "            \n",
    "            # Update every 1 second\n",
    "            self.window.after(1000, self.update_stopwatch)\n",
    "    \n",
    "    def update(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        \n",
    "        if ret:\n",
    "            # Process frame if logging is active\n",
    "            if self.is_running:\n",
    "                self.process_frame(frame)\n",
    "            \n",
    "            # Convert to RGB for display\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img = PIL.Image.fromarray(frame_rgb)\n",
    "            \n",
    "            # Resize to fit canvas\n",
    "            canvas_width = self.canvas.winfo_width()\n",
    "            canvas_height = self.canvas.winfo_height()\n",
    "            \n",
    "            if canvas_width > 1 and canvas_height > 1:\n",
    "                ratio = min(canvas_width/img.width, canvas_height/img.height)\n",
    "                new_width = int(img.width * ratio)\n",
    "                new_height = int(img.height * ratio)\n",
    "                img = img.resize((new_width, new_height), PIL.Image.Resampling.LANCZOS)\n",
    "            \n",
    "            self.photo = PIL.ImageTk.PhotoImage(image=img)\n",
    "            self.canvas.create_image(canvas_width//2, canvas_height//2, image=self.photo, anchor=tk.CENTER)\n",
    "        \n",
    "        if not self.stop_event.is_set():\n",
    "            self.window.after(10, self.update)\n",
    "    \n",
    "    def process_frame(self, frame):\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Initialize the 5-second logging interval\n",
    "        if self.last_log_time is None:\n",
    "            self.last_log_time = current_time\n",
    "        \n",
    "        # Process frame for emotion detection\n",
    "        frame_copy = frame.copy()\n",
    "        frame_copy.flags.writeable = False\n",
    "        frame_copy = cv2.cvtColor(frame_copy, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        with self.mp_face_mesh.FaceMesh(\n",
    "            max_num_faces=1,\n",
    "            refine_landmarks=False,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5) as face_mesh:\n",
    "            \n",
    "            results = face_mesh.process(frame_copy)\n",
    "            \n",
    "            if results.multi_face_landmarks:\n",
    "                for fl in results.multi_face_landmarks:\n",
    "                    h, w, _ = frame_copy.shape\n",
    "                    startX, startY, endX, endY = get_box(fl, w, h)\n",
    "                    \n",
    "                    # Extract face\n",
    "                    cur_face = frame_copy[startY:endY, startX:endX]\n",
    "                    if cur_face.size == 0:  # Skip if face not properly detected\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        # Process with model\n",
    "                        cur_face = pth_processing(Image.fromarray(cur_face))\n",
    "                        features = torch.nn.functional.relu(self.pth_backbone_model.extract_features(cur_face)).detach().numpy()\n",
    "                        \n",
    "                        # Update LSTM features\n",
    "                        if len(self.lstm_features) == 0:\n",
    "                            self.lstm_features = [features] * 10\n",
    "                        else:\n",
    "                            self.lstm_features = self.lstm_features[1:] + [features]\n",
    "                        \n",
    "                        lstm_f = torch.from_numpy(np.vstack(self.lstm_features))\n",
    "                        lstm_f = torch.unsqueeze(lstm_f, 0)\n",
    "                        output = self.pth_LSTM_model(lstm_f).detach().numpy()\n",
    "                        \n",
    "                        # Get emotion label\n",
    "                        cl = np.argmax(output)\n",
    "                        emotion = self.DICT_EMO[cl]\n",
    "                        confidence = output[0][cl]\n",
    "                        \n",
    "                        # Add to current emotions\n",
    "                        self.current_emotions.append(emotion)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing face: {e}\")\n",
    "        \n",
    "        # Log emotions every 5 seconds\n",
    "        if current_time - self.last_log_time >= 5 and self.current_emotions:\n",
    "            self.log_emotions()\n",
    "            self.last_log_time = current_time\n",
    "    \n",
    "    def log_emotions(self):\n",
    "        if not self.current_emotions:\n",
    "            return\n",
    "        \n",
    "        # Count occurrences of each emotion\n",
    "        emotion_counts = Counter(self.current_emotions)\n",
    "        dominant_emotion = emotion_counts.most_common(1)[0][0]\n",
    "        \n",
    "        # Check for negative emotions\n",
    "        negative_emotions = [emotion for emotion in self.current_emotions if emotion in self.NEGATIVE_EMOTIONS]\n",
    "        has_negative = len(negative_emotions) > 0\n",
    "        \n",
    "        # Create log entry\n",
    "        elapsed_time = int(time.time() - self.logging_start_time)\n",
    "        timestamp = f\"{elapsed_time//60:02d}:{elapsed_time%60:02d}\"\n",
    "        \n",
    "        log_entry = {\n",
    "            \"timestamp\": timestamp,\n",
    "            \"dominant_emotion\": dominant_emotion,\n",
    "            \"counts\": dict(emotion_counts),\n",
    "            \"has_negative\": has_negative\n",
    "        }\n",
    "        \n",
    "        self.emotion_logs.append(log_entry)\n",
    "        \n",
    "        # Clear current emotions for next interval\n",
    "        self.current_emotions = []\n",
    "    \n",
    "    def start_logging(self):\n",
    "        self.is_running = True\n",
    "        self.logging_start_time = time.time()\n",
    "        self.last_log_time = None\n",
    "        self.emotion_logs = []\n",
    "        self.speech_logs = []\n",
    "        self.current_emotions = []\n",
    "        \n",
    "        # Start audio processing\n",
    "        self.audio_processor.start_recording()\n",
    "        \n",
    "        # Start stopwatch\n",
    "        self.stopwatch_active = True\n",
    "        self.update_stopwatch()\n",
    "        \n",
    "        # Update UI\n",
    "        self.status_label.config(text=\"Logging\")\n",
    "        self.start_button.config(state=tk.DISABLED)\n",
    "        self.stop_button.config(state=tk.NORMAL)\n",
    "        self.reset_button.config(state=tk.DISABLED)\n",
    "        self.choose_file_button.config(state=tk.DISABLED)  # Disable file selection during recording\n",
    "        \n",
    "        # Clear summary\n",
    "        self.summary_text.config(state=tk.NORMAL)\n",
    "        self.summary_text.delete(1.0, tk.END)\n",
    "        self.summary_text.insert(tk.END, \"Logging emotions and voice metrics...\\n\")\n",
    "        self.summary_text.config(state=tk.DISABLED)\n",
    "    \n",
    "    def stop_logging(self):\n",
    "        if self.is_running:\n",
    "            self.is_running = False\n",
    "            self.stopwatch_active = False\n",
    "            \n",
    "            # Stop audio recording and process final audio\n",
    "            self.audio_processor.stop_recording()\n",
    "            \n",
    "            # Log any remaining emotions\n",
    "            if self.current_emotions:\n",
    "                self.log_emotions()\n",
    "            \n",
    "            # Update UI\n",
    "            self.status_label.config(text=\"Ready\")\n",
    "            self.start_button.config(state=tk.DISABLED)\n",
    "            self.stop_button.config(state=tk.DISABLED)\n",
    "            self.reset_button.config(state=tk.NORMAL)\n",
    "            self.choose_file_button.config(state=tk.NORMAL)  # Re-enable file selection\n",
    "            \n",
    "            # Generate and display summary\n",
    "            self.display_summary()\n",
    "            \n",
    "            # Save video summary to text file\n",
    "            self.save_video_summary()\n",
    "            # Save audio summary to text file\n",
    "            self.save_audio_summary()\n",
    "    \n",
    "    def save_video_summary(self):\n",
    "        \"\"\"Save the video summary to a text file.\"\"\"\n",
    "        try:\n",
    "            with open(\"video_logging.txt\", \"w\") as file:\n",
    "                file.write(\"== Emotion Logging Summary ==\\n\")\n",
    "                \n",
    "                # Format final time\n",
    "                hours, remainder = divmod(int(self.elapsed_time), 3600)\n",
    "                minutes, seconds = divmod(remainder, 60)\n",
    "                time_str = f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "                file.write(f\"Total Duration: {time_str}\\n\")\n",
    "                \n",
    "                # Log 5-second intervals\n",
    "                file.write(\"=== 5-second Intervals ===\\n\")\n",
    "                for log in self.emotion_logs:\n",
    "                    file.write(f\"[{log['timestamp']}] Dominant: {log['dominant_emotion']}\\n\")\n",
    "                    #if log['has_negative']:\n",
    "                        #file.write(\"⚠️ Negative emotions detected!\\n\")\n",
    "                    for emotion, count in log['counts'].items():\n",
    "                        percentage = count / sum(log['counts'].values()) * 100\n",
    "                        file.write(f\"* {emotion}: {percentage:.1f}%\\n\")\n",
    "                \n",
    "                # Overall summary\n",
    "                file.write(\"=== Overall Summary ===\\n\")\n",
    "                if self.emotion_logs:\n",
    "                    dominant_counts = Counter([log['dominant_emotion'] for log in self.emotion_logs])\n",
    "                    most_common = dominant_counts.most_common()\n",
    "                    file.write(\"Most frequent emotions:\\n\")\n",
    "                    for emotion, count in most_common:\n",
    "                        percentage = count / len(self.emotion_logs) * 100\n",
    "                        file.write(f\"* {emotion}: {percentage:.1f}%\\n\")\n",
    "                    \n",
    "                    negative_intervals = sum(1 for log in self.emotion_logs if log['has_negative'])\n",
    "                    neg_percentage = negative_intervals / len(self.emotion_logs) * 100\n",
    "                    #file.write(f\"⚠️ Negative emotions detected in {negative_intervals} intervals ({neg_percentage:.1f}%)\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving video summary: {e}\")\n",
    "    \n",
    "    def save_audio_summary(self):\n",
    "        \"\"\"Save the audio summary to a text file.\"\"\"\n",
    "        try:\n",
    "            with open(\"audio_logging.txt\", \"w\") as f:\n",
    "                f.write(\"== voice attribute Logging Summary ==\\n\")\n",
    "                # total duration\n",
    "                hours, rem = divmod(int(self.elapsed_time), 3600)\n",
    "                mins, secs = divmod(rem, 60)\n",
    "                f.write(f\"Total Duration: {hours:02d}:{mins:02d}:{secs:02d}\\n\")\n",
    "                f.write(\"=== 5-second Intervals ===\\n\")\n",
    "                from collections import Counter\n",
    "                doms = []\n",
    "                # iterate through each logged audio entry\n",
    "                for idx, log in enumerate(self.speech_logs, start=1):\n",
    "                    dom_emotion = max(log['emotions'], key=log['emotions'].get)\n",
    "                    doms.append(dom_emotion)\n",
    "                    f.write(f\"[Interval {idx}] Dominant: {dom_emotion}\\n\\n\")\n",
    "                    # write each emotion and metric\n",
    "                    # for k, v in {**log['emotions'], **log['metrics']}.items():\n",
    "                    #     f.write(f\"{k}: {v:.1f}\\n\")\n",
    "                    # f.write(\"\\n\")\n",
    "                    # Only write relevant metrics/emotions\n",
    "                    for k, v in {**log['emotions'], **log['metrics']}.items():\n",
    "                        if k in [\"samples_processed\", \"volume_db\"]:\n",
    "                            continue  # Skip these keys\n",
    "                        if k == \"volume\":\n",
    "                            scaled_volume = v * 100\n",
    "                            f.write(f\"volume: {scaled_volume:.1f}\\n\")\n",
    "                        else:\n",
    "                            f.write(f\"{k}: {v:.1f}\\n\")\n",
    "                # overall summary\n",
    "                # f.write(\"=== Overall Summary ===\\n\")\n",
    "                # f.write(\"Most frequent emotions:\\n\")\n",
    "                # counts = Counter(doms)\n",
    "                # for em, cnt in counts.items():\n",
    "                #     pct = cnt / len(doms) * 100 if doms else 0\n",
    "                #     f.write(f\"{em}: {pct:.1f}%\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving audio summary: {e}\")\n",
    "    \n",
    "    def reset_logging(self):\n",
    "        # Reset all variables to initial state\n",
    "        self.emotion_logs = []\n",
    "        self.speech_logs = []\n",
    "        self.current_emotions = []\n",
    "        self.logging_start_time = None\n",
    "        self.last_log_time = None\n",
    "        self.elapsed_time = 0\n",
    "        self.lstm_features = []\n",
    "        \n",
    "        # Overwrite the video summary file\n",
    "        try:\n",
    "            with open(\"video_logging.txt\", \"w\") as file:\n",
    "                file.write(\"Ready for new logging session.\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error resetting video summary file: {e}\")\n",
    "        \n",
    "        # Reset UI\n",
    "        self.time_label.config(text=\"00:00:00\")\n",
    "        self.status_label.config(text=\"Ready\")\n",
    "        self.start_button.config(state=tk.NORMAL)\n",
    "        self.stop_button.config(state=tk.DISABLED)\n",
    "        self.reset_button.config(state=tk.DISABLED)\n",
    "        \n",
    "        # Reset voice metrics\n",
    "        for metric in [\"confidence\", \"enthusiasm\", \"clarity\", \"speaking rate\"]:\n",
    "            self.voice_labels[metric].config(text=\"N/A\")\n",
    "            self.voice_labels[f\"{metric}_bar\"][\"value\"] = 0\n",
    "        \n",
    "        # Clear summary\n",
    "        self.summary_text.config(state=tk.NORMAL)\n",
    "        self.summary_text.delete(1.0, tk.END)\n",
    "        self.summary_text.insert(tk.END, \"Ready to start a new session.\\n\")\n",
    "        self.summary_text.config(state=tk.DISABLED)\n",
    "    \n",
    "    def display_summary(self):\n",
    "        self.summary_text.config(state=tk.NORMAL)\n",
    "        self.summary_text.delete(1.0, tk.END)\n",
    "        \n",
    "        if not self.emotion_logs and not self.speech_logs:\n",
    "            self.summary_text.insert(tk.END, \"No data logged.\")\n",
    "            self.summary_text.config(state=tk.DISABLED)\n",
    "            return\n",
    "        \n",
    "        # Format final time\n",
    "        hours, remainder = divmod(int(self.elapsed_time), 3600)\n",
    "        minutes, seconds = divmod(remainder, 60)\n",
    "        time_str = f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "        \n",
    "        self.summary_text.insert(tk.END, f\"== Presentation Analysis Summary ==\\n\")\n",
    "        self.summary_text.insert(tk.END, f\"Total Duration: {time_str}\\n\")\n",
    "        self.summary_text.insert(tk.END, f\"Facial emotion tracking interval: 5 seconds\\n\")\n",
    "        \n",
    "        # Add transcript file info if available\n",
    "        if self.transcript_file_path:\n",
    "            filename = os.path.basename(self.transcript_file_path)\n",
    "            self.summary_text.insert(tk.END, f\"Transcript: {filename}\\n\")\n",
    "        \n",
    "        self.summary_text.insert(tk.END, \"\\n\")\n",
    "        \n",
    "        # Visual emotion summary\n",
    "        if self.emotion_logs:\n",
    "            self.summary_text.insert(tk.END, \"=== Visual Emotion Analysis ===\\n\")\n",
    "            \n",
    "            # Count dominant emotions across all intervals\n",
    "            dominant_counts = Counter([log['dominant_emotion'] for log in self.emotion_logs])\n",
    "            most_common = dominant_counts.most_common()\n",
    "            \n",
    "            self.summary_text.insert(tk.END, \"Most frequent facial emotions:\\n\")\n",
    "            for emotion, count in most_common:\n",
    "                percentage = count / len(self.emotion_logs) * 100\n",
    "                self.summary_text.insert(tk.END, f\"  - {emotion}: {percentage:.1f}%\\n\")\n",
    "            \n",
    "            # Check for negative emotions\n",
    "            negative_intervals = sum(1 for log in self.emotion_logs if log['has_negative'])\n",
    "            if negative_intervals > 0:\n",
    "                neg_percentage = negative_intervals / len(self.emotion_logs) * 100\n",
    "                self.summary_text.insert(tk.END, f\"\\n⚠️ Negative facial expressions detected in {negative_intervals} intervals ({neg_percentage:.1f}%)\\n\")\n",
    "            else:\n",
    "                self.summary_text.insert(tk.END, \"\\n✅ No negative facial expressions detected\\n\")\n",
    "        \n",
    "        # Voice analysis summary\n",
    "        if self.speech_logs:\n",
    "            self.summary_text.insert(tk.END, \"\\n=== Voice Analysis ===\\n\")\n",
    "            \n",
    "            # Get the latest speech metrics (most comprehensive)\n",
    "            latest_speech = self.speech_logs[-1]\n",
    "            \n",
    "            # Confidence\n",
    "            confidence = latest_speech[\"emotions\"][\"confidence\"] * 100\n",
    "            self.summary_text.insert(tk.END, f\"Voice Confidence: {confidence:.1f}%\\n\")\n",
    "            \n",
    "            # Enthusiasm\n",
    "            enthusiasm = latest_speech[\"emotions\"][\"enthusiasm\"] * 100\n",
    "            self.summary_text.insert(tk.END, f\"Voice Enthusiasm: {enthusiasm:.1f}%\\n\")\n",
    "            \n",
    "            # Speaking rate\n",
    "            speaking_rate = latest_speech[\"metrics\"][\"speaking_rate\"]\n",
    "            rate_description = \"Too slow\" if speaking_rate < 5 else \"Good\" if speaking_rate < 15 else \"Too fast\"\n",
    "            self.summary_text.insert(tk.END, f\"Speaking Rate: {speaking_rate:.1f} ({rate_description})\\n\")\n",
    "            \n",
    "            # Clarity\n",
    "            clarity = latest_speech[\"metrics\"][\"clarity\"] * 100\n",
    "            self.summary_text.insert(tk.END, f\"Voice Clarity: {clarity:.1f}%\\n\")\n",
    "            \n",
    "            # Hesitation\n",
    "            hesitation = latest_speech[\"emotions\"][\"hesitation\"] * 100\n",
    "            if hesitation > 40:\n",
    "                self.summary_text.insert(tk.END, f\"⚠️ High hesitation detected ({hesitation:.1f}%)\\n\")\n",
    "        \n",
    "        # Combined analysis and advice\n",
    "        self.summary_text.insert(tk.END, \"\\n=== Presentation Advice ===\\n\")\n",
    "        \n",
    "        # Generate personalized advice based on both facial and voice analysis\n",
    "        if self.emotion_logs and self.speech_logs:\n",
    "            # Get key metrics\n",
    "            latest_speech = self.speech_logs[-1]\n",
    "            confidence = latest_speech[\"emotions\"][\"confidence\"]\n",
    "            enthusiasm = latest_speech[\"emotions\"][\"enthusiasm\"]\n",
    "            hesitation = latest_speech[\"emotions\"][\"hesitation\"]\n",
    "            speaking_rate = latest_speech[\"metrics\"][\"speaking_rate\"]\n",
    "            \n",
    "            negative_face_percent = 0\n",
    "            if self.emotion_logs:\n",
    "                negative_intervals = sum(1 for log in self.emotion_logs if log['has_negative'])\n",
    "                negative_face_percent = negative_intervals / len(self.emotion_logs) if self.emotion_logs else 0\n",
    "            \n",
    "            # Generate personalized advice\n",
    "            if negative_face_percent > 0.3 and confidence < 0.5:\n",
    "                self.summary_text.insert(tk.END, \"Your facial expressions show nervousness and your voice lacks confidence. \")\n",
    "                self.summary_text.insert(tk.END, \"Practice more to build confidence. Consider recording yourself and watching the playback. \")\n",
    "                self.summary_text.insert(tk.END, \"Focus on deep breathing exercises before presenting.\\n\")\n",
    "            elif confidence < 0.4:\n",
    "                self.summary_text.insert(tk.END, \"Your voice shows low confidence. Try to speak more assertively. \")\n",
    "                self.summary_text.insert(tk.END, \"Practice power posing before your presentation and speak from your diaphragm.\\n\")\n",
    "            elif enthusiasm < 0.4:\n",
    "                self.summary_text.insert(tk.END, \"Your presentation lacks vocal enthusiasm. Add more vocal variety and emphasis on key points. \")\n",
    "                self.summary_text.insert(tk.END, \"Try varying your pitch and pace to keep your audience engaged.\\n\")\n",
    "            elif hesitation > 0.6:\n",
    "                self.summary_text.insert(tk.END, \"You show significant hesitation in your speech. Practice your presentation more thoroughly \")\n",
    "                self.summary_text.insert(tk.END, \"to reduce pauses and filler words like 'um' and 'uh'.\\n\")\n",
    "            elif speaking_rate > 15:\n",
    "                self.summary_text.insert(tk.END, \"You're speaking too quickly. Slow down to improve clarity and give your audience time to process. \")\n",
    "                self.summary_text.insert(tk.END, \"Try marking your script with deliberate pause points.\\n\")\n",
    "            elif speaking_rate < 5:\n",
    "                self.summary_text.insert(tk.END, \"Your pace is quite slow. Try to increase your speaking rate slightly to maintain audience engagement. \")\n",
    "                self.summary_text.insert(tk.END, \"Practice with a timer to find a better rhythm.\\n\")\n",
    "            elif confidence > 0.7 and enthusiasm > 0.7 and hesitation < 0.3:\n",
    "                self.summary_text.insert(tk.END, \"Excellent job! Your voice projects confidence and enthusiasm, and your facial expressions are positive. \")\n",
    "                self.summary_text.insert(tk.END, \"Maintain this energy level for your actual presentation.\\n\")\n",
    "            else:\n",
    "                self.summary_text.insert(tk.END, \"Your presentation shows good elements but has room for improvement. \")\n",
    "                self.summary_text.insert(tk.END, \"Focus on maintaining consistent energy and confidence throughout.\\n\")\n",
    "        \n",
    "        # Additional specific advice\n",
    "        self.summary_text.insert(tk.END, \"\\nPractice Tips:\\n\")\n",
    "        self.summary_text.insert(tk.END, \"1. Record yourself and review your performance\\n\")\n",
    "        self.summary_text.insert(tk.END, \"2. Practice in front of friends or colleagues\\n\")\n",
    "        self.summary_text.insert(tk.END, \"3. Time your presentation sections\\n\")\n",
    "        self.summary_text.insert(tk.END, \"4. Use breathing exercises before presenting\\n\")\n",
    "        self.summary_text.insert(tk.END, \"5. Remember to pause at key points\\n\")\n",
    "        \n",
    "        self.summary_text.config(state=tk.DISABLED)\n",
    "    \n",
    "    def on_closing(self):\n",
    "        self.stop_event.set()\n",
    "        if hasattr(self, 'audio_processor'):\n",
    "            self.audio_processor.stop_recording()\n",
    "        if self.cap and self.cap.isOpened():\n",
    "            self.cap.release()\n",
    "        self.window.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "444b94e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid command name \"13523222784update\"\n",
      "    while executing\n",
      "\"13523222784update\"\n",
      "    (\"after\" script)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio recording started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1752451978.580966 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451978.582856 5998252 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451978.585849 5998253 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451978.710087 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451978.711329 5998263 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451978.713161 5998266 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451978.847553 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451978.848478 5998273 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451978.850501 5998276 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451978.973742 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451978.974713 5998280 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451978.976847 5998281 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451979.110976 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451979.112143 5998295 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451979.114377 5998300 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451979.240763 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451979.241755 5998309 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451979.243644 5998309 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451979.379047 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451979.379921 5998319 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451979.381541 5998323 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451979.509460 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451979.510531 5998328 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451979.514233 5998325 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451979.651420 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451979.652491 5998342 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451979.654389 5998338 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451979.780879 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451979.781801 5998351 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451979.784228 5998353 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451979.911143 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451979.912169 5998361 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451979.913827 5998361 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451980.040652 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451980.041569 5998370 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451980.043432 5998368 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451980.193936 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451980.194948 5998382 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451980.196938 5998382 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451980.320740 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451980.321873 5998408 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451980.323450 5998408 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451980.453269 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451980.454320 5998420 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451980.456496 5998420 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451980.582240 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451980.583503 5998428 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451980.585338 5998428 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451980.740041 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451980.741060 5998441 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451980.742671 5998441 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451980.871885 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451980.872739 5998450 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451980.874829 5998448 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451981.014112 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451981.015219 5998461 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451981.017383 5998462 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451981.143847 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451981.145299 5998469 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451981.146801 5998469 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451981.278905 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451981.280217 5998479 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451981.281758 5998479 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451981.409975 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451981.410970 5998488 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451981.413115 5998487 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451981.541479 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451981.542908 5998496 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451981.544758 5998496 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451981.678812 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451981.680311 5998502 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451981.682306 5998505 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451981.811803 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451981.813008 5998510 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451981.814697 5998510 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451981.941969 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451981.942826 5998521 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451981.944448 5998520 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451982.073074 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451982.074423 5998530 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451982.076029 5998530 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451982.205417 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451982.206342 5998539 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451982.207942 5998537 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451982.345226 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451982.346054 5998550 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451982.348854 5998552 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451982.495136 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451982.496086 5998577 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451982.498669 5998580 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451982.627990 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451982.629585 5998589 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451982.631155 5998589 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451982.758577 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451982.759648 5998593 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451982.761197 5998593 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451982.890303 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451982.891138 5998600 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451982.893625 5998601 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451983.038129 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451983.039505 5998612 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451983.041212 5998614 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451983.168815 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451983.169739 5998620 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451983.171462 5998620 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451983.303939 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451983.304785 5998631 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451983.306976 5998630 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451983.433212 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451983.434327 5998638 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451983.435978 5998639 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451983.564889 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451983.565869 5998651 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451983.567992 5998650 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451983.702868 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451983.703789 5998657 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451983.705604 5998654 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451983.835005 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451983.835891 5998665 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451983.837640 5998668 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451983.966046 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451983.967115 5998678 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451983.968794 5998678 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451984.093336 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451984.094258 5998687 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451984.095974 5998688 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451984.222272 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451984.223170 5998696 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451984.224796 5998696 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451984.351653 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451984.353089 5998704 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451984.354816 5998705 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451984.480270 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451984.481192 5998728 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451984.483458 5998727 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451984.611110 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451984.612004 5998735 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451984.613956 5998739 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451984.745261 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451984.746301 5998744 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451984.748335 5998744 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451984.875917 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451984.876821 5998754 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451984.878366 5998754 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451985.019626 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451985.020667 5998764 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451985.022358 5998764 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451985.150504 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451985.151430 5998774 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451985.153275 5998778 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451985.281090 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451985.282568 5998784 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451985.284189 5998784 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451985.412106 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451985.413009 5998792 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451985.414815 5998790 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451985.544717 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451985.545675 5998800 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451985.547214 5998800 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451985.681508 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451985.682413 5998807 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451985.684572 5998808 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451985.813179 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451985.814684 5998817 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451985.816312 5998821 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451985.946146 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451985.946963 5998826 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451985.949459 5998825 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451986.083402 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451986.084270 5998836 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451986.086775 5998837 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451986.211418 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451986.212280 5998846 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451986.213874 5998846 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451986.343423 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451986.344284 5998856 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451986.346158 5998856 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451986.485769 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451986.486701 5998863 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451986.488499 5998867 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451986.613977 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451986.615089 5998886 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451986.616932 5998886 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451986.747090 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451986.748671 5998895 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451986.750270 5998895 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451986.878205 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451986.879274 5998903 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451986.881021 5998903 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451987.018633 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451987.020188 5998918 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451987.021818 5998922 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451987.148099 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451987.149055 5998926 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451987.150899 5998925 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451987.274650 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451987.276255 5998935 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451987.277702 5998932 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451987.412073 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451987.413892 5998943 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451987.415962 5998947 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451987.547402 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451987.548331 5998950 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451987.550018 5998955 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451987.681338 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451987.682455 5998957 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451987.684932 5998957 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451987.814025 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451987.814883 5998966 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451987.816513 5998965 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451987.945337 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451987.946225 5998975 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451987.947910 5998981 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451988.091234 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451988.092282 5998999 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451988.094583 5999001 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451988.218879 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451988.220361 5999011 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451988.222311 5999011 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451988.349310 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451988.350378 5999018 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451988.352107 5999018 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451988.476321 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451988.477191 5999026 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451988.478897 5999029 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451988.613426 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451988.614260 5999036 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451988.616781 5999037 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451988.754457 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451988.755278 5999059 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451988.757756 5999060 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451988.887810 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451988.888664 5999068 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451988.890290 5999068 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451989.016286 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451989.017268 5999076 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451989.019730 5999075 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451989.149225 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451989.150231 5999082 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451989.152860 5999082 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451989.284563 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451989.286217 5999092 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451989.287868 5999092 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451989.417775 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451989.418842 5999104 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451989.420588 5999104 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451989.546994 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451989.547874 5999114 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451989.549713 5999113 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451989.685618 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451989.686538 5999123 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451989.688271 5999125 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451989.839074 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451989.840081 5999131 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451989.841743 5999131 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451989.972089 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451989.973596 5999163 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451989.975325 5999163 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451990.099816 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451990.101500 5999172 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451990.103146 5999172 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451990.228016 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451990.228945 5999178 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451990.231113 5999180 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451990.358014 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451990.359753 5999188 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451990.361635 5999185 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451990.488035 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451990.489500 5999195 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451990.491727 5999195 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451990.617161 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451990.618123 5999204 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451990.619829 5999205 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451990.748982 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451990.750812 5999212 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451990.752390 5999214 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451990.880457 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451990.881404 5999236 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451990.883168 5999236 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451991.010006 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451991.011721 5999245 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451991.013371 5999245 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451991.153652 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451991.155167 5999253 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451991.156808 5999253 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451991.281449 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451991.282310 5999263 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451991.284580 5999265 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752451991.417141 5994918 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1752451991.418275 5999273 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752451991.420043 5999273 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio recording stopped\n"
     ]
    }
   ],
   "source": [
    "# Run the application\n",
    "root = tk.Tk()\n",
    "app = EmotionLoggingApp(root, \"Presentation Rehearsal Voice & Emotion Tracker\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
